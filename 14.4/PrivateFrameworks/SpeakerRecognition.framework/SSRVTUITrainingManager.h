//
//     Generated by classdumpios 1.0.1 (64 bit) (iOS port by DreamDevLost)(Debug version compiled Sep 26 2020 13:48:20).
//
//  Copyright (C) 1997-2019 Steve Nygard.
//

#import <objc/NSObject.h>

#import <SpeakerRecognition/CSEndpointAnalyzerDelegate-Protocol.h>
#import <SpeakerRecognition/CSVTUIAudioSessionDelegate-Protocol.h>
#import <SpeakerRecognition/CSVTUITrainingSessionDelegate-Protocol.h>

@class CSAsset, CSDispatchGroup, CSNNVADEndpointAnalyzer, CSPlainAudioFileWriter, CSVTUIKeywordDetector, CSVTUITrainingSession, NSMutableArray, NSString, SFSpeechRecognizer, SSRVoiceProfile;
@protocol CSVTUIAudioSession, OS_dispatch_queue, SSRVTUITrainingManagerDelegate;

@interface SSRVTUITrainingManager : NSObject <CSVTUITrainingSessionDelegate, CSVTUIAudioSessionDelegate, CSEndpointAnalyzerDelegate>
{
    _Bool _performRMS;
    NSString *_locale;
    id <CSVTUIAudioSession> _audioSession;
    CSNNVADEndpointAnalyzer *_audioAnalyzer;
    CSVTUIKeywordDetector *_keywordDetector;
    NSMutableArray *_trainingSessions;
    CSVTUITrainingSession *_currentTrainingSession;
    long long _sessionNumber;
    _Bool _suspendAudio;
    NSObject<OS_dispatch_queue> *_queue;
    CDUnknownBlockType _cleanupCompletion;
    SFSpeechRecognizer *_speechRecognizer;
    CSAsset *_currentAsset;
    SSRVoiceProfile *_profile;
    CSDispatchGroup *_didStopWaitingGroup;
    _Bool _speechRecognizerAvailable;
    float _rms;
    id <SSRVTUITrainingManagerDelegate> _delegate;
    CSPlainAudioFileWriter *_audioFileWriter;
}

+ (id)sharedtrainingSessionQueue;
+ (id)trainingManagerWithLocaleID:(id)arg1 withAppDomain:(id)arg2;
- (void).cxx_destruct;
@property(retain, nonatomic) CSPlainAudioFileWriter *audioFileWriter; // @synthesize audioFileWriter=_audioFileWriter;
@property(readonly) _Bool speechRecognizerAvailable; // @synthesize speechRecognizerAvailable=_speechRecognizerAvailable;
@property(nonatomic) __weak id <SSRVTUITrainingManagerDelegate> delegate; // @synthesize delegate=_delegate;
@property float rms; // @synthesize rms=_rms;
- (void)didDetectForceEndPoint;
- (void)endpointer:(id)arg1 didDetectHardEndpointAtTime:(double)arg2 withMetrics:(id)arg3;
- (void)endpointer:(id)arg1 didDetectStartpointAtTime:(double)arg2;
- (void)audioSessionUnsupportedAudioRoute;
- (void)audioSessionErrorDidOccur:(id)arg1;
- (void)audioSessionRecordBufferAvailable:(id)arg1;
- (void)audioSessionDidStopRecording:(long long)arg1;
- (void)audioSessionDidStartRecording:(_Bool)arg1 error:(id)arg2;
- (_Bool)CSVTUITrainingSession:(id)arg1 hasTrainUtterance:(id)arg2 languageCode:(id)arg3 payload:(_Bool)arg4;
- (void)CSVTUITrainingSessionStopListen;
- (void)CSVTUITrainingSessionRMSAvailable:(float)arg1;
- (_Bool)shouldPerformRMS;
- (void)stopRMS;
- (void)startRMS;
@property _Bool suspendAudio;
- (_Bool)_startAudioSession;
- (_Bool)_shouldShowHeadsetDisconnectionMessage;
- (_Bool)_createAudioAnalyzer;
- (_Bool)_setupAudioSession;
- (unsigned long long)_audioSource;
@property(readonly) unsigned long long audioSource;
- (void)closeSessionBeforeStartWithStatus:(int)arg1 successfully:(_Bool)arg2 withCompletion:(CDUnknownBlockType)arg3;
- (_Bool)cancelTrainingForID:(long long)arg1;
- (void)reset;
- (long long)trainUtterance:(long long)arg1 shouldUseASR:(_Bool)arg2 completion:(CDUnknownBlockType)arg3;
- (void)destroySpeakerTrainer;
- (id)cleanupWithCompletion:(CDUnknownBlockType)arg1;
- (void)_endOfSpeechDetected;
- (void)_beginOfSpeechDetected;
- (void)_destroyAudioSession;
- (_Bool)_stopAudioSession;
- (void)prepareWithCompletion:(CDUnknownBlockType)arg1;
- (void)createSpeechRecognizer;
- (_Bool)createKeywordDetector;
- (void)setLocaleIdentifier:(id)arg1;
- (id)initWithLocaleIdentifier:(id)arg1 withAudioSession:(id)arg2 withAppDomain:(id)arg3;
@property(readonly) SSRVoiceProfile *voiceProfile;

// Remaining properties
@property(readonly, copy) NSString *debugDescription;
@property(readonly, copy) NSString *description;
@property(readonly) unsigned long long hash;
@property(readonly) Class superclass;

@end

