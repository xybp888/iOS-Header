//
//     Generated by class-dump 3.5 (64 bit).
//
//  Copyright (C) 1997-2019 Steve Nygard.
//
//  Build 2022-10-30 xybp888 Dump.
//  

#import <objc/NSObject.h>

@class NSString, VCPVNImageprintWrapper;

__attribute__((visibility("hidden")))
@interface VCPPhotosFace : NSObject
{
    _Bool _hidden;
    _Bool _isInTrash;
    _Bool _manual;
    _Bool _isTooSmall;
    _Bool _hasSmile;
    _Bool _isLeftEyeClosed;
    _Bool _isRightEyeClosed;
    _Bool _hasFaceMask;
    short _detectionType;
    unsigned short _ageType;
    unsigned short _sexType;
    unsigned short _eyesState;
    unsigned short _smileType;
    unsigned short _facialHairType;
    unsigned short _hairColorType;
    unsigned short _glassesType;
    unsigned short _expressionType;
    unsigned short _headgearType;
    unsigned short _hairType;
    unsigned short _poseType;
    unsigned short _skintoneType;
    unsigned short _ethnicityType;
    unsigned short _gazeType;
    int _trainingType;
    NSString *_localIdentifier;
    NSString *_personLocalIdentifier;
    long long _sourceWidth;
    long long _sourceHeight;
    double _centerX;
    double _centerY;
    double _size;
    double _bodyCenterX;
    double _bodyCenterY;
    double _bodyWidth;
    double _bodyHeight;
    double _blurScore;
    double _exposureScore;
    NSString *_adjustmentVersion;
    long long _nameSource;
    double _poseYaw;
    unsigned long long _algorithmVersion;
    long long _clusterSequenceNumber;
    long long _qualityMeasure;
    double _gazeCenterX;
    double _gazeCenterY;
    NSString *_groupingIdentifier;
    VCPVNImageprintWrapper *_imageprintWrapper;
    double _roll;
    double _quality;
}

+ (_Bool)_isColocatingAnimalObservation:(id)arg1 withFaceObservations:(id)arg2 orTorsoObservations:(id)arg3;
+ (double)_calculateIoUBetweenObservation:(id)arg1 andObservation:(id)arg2;
+ (double)_calculateOverlappingBetweenFaceObservation:(id)arg1 andHumanObservation:(id)arg2;
+ (id)facesFromPHFetchResult:(id)arg1 copyOption:(long long)arg2;
+ (id)faceFromPHFace:(id)arg1 copyOption:(long long)arg2;
+ (id)facesFromFaceObservations:(id)arg1 humanObservations:(id)arg2 animalObservations:(id)arg3 sourceWidth:(unsigned long long)arg4 sourceHeight:(unsigned long long)arg5 visionRequests:(id)arg6 blurScorePerFace:(id)arg7 exposureScorePerFace:(id)arg8 tooSmallFaceObservations:(id)arg9 processingVersion:(int)arg10;
+ (id)faceFromFaceObservation:(id)arg1 humanObservation:(id)arg2 sourceWidth:(unsigned long long)arg3 sourceHeight:(unsigned long long)arg4 visionRequests:(id)arg5 processingVersion:(int)arg6 force:(_Bool)arg7 andError:(id *)arg8;
+ (id)faceWithLocalIdentifier:(id)arg1;
- (void).cxx_destruct;
@property(nonatomic) double quality; // @synthesize quality=_quality;
@property(nonatomic) double roll; // @synthesize roll=_roll;
@property(retain, nonatomic) VCPVNImageprintWrapper *imageprintWrapper; // @synthesize imageprintWrapper=_imageprintWrapper;
@property(copy, nonatomic) NSString *groupingIdentifier; // @synthesize groupingIdentifier=_groupingIdentifier;
@property(nonatomic) double gazeCenterY; // @synthesize gazeCenterY=_gazeCenterY;
@property(nonatomic) double gazeCenterX; // @synthesize gazeCenterX=_gazeCenterX;
@property(nonatomic) unsigned short gazeType; // @synthesize gazeType=_gazeType;
@property(nonatomic) _Bool hasFaceMask; // @synthesize hasFaceMask=_hasFaceMask;
@property(nonatomic) unsigned short ethnicityType; // @synthesize ethnicityType=_ethnicityType;
@property(nonatomic) unsigned short skintoneType; // @synthesize skintoneType=_skintoneType;
@property(nonatomic) unsigned short poseType; // @synthesize poseType=_poseType;
@property(nonatomic) unsigned short hairType; // @synthesize hairType=_hairType;
@property(nonatomic) unsigned short headgearType; // @synthesize headgearType=_headgearType;
@property(nonatomic) unsigned short expressionType; // @synthesize expressionType=_expressionType;
@property(nonatomic) unsigned short glassesType; // @synthesize glassesType=_glassesType;
@property(nonatomic) unsigned short hairColorType; // @synthesize hairColorType=_hairColorType;
@property(nonatomic) unsigned short facialHairType; // @synthesize facialHairType=_facialHairType;
@property(nonatomic) unsigned short smileType; // @synthesize smileType=_smileType;
@property(nonatomic) unsigned short eyesState; // @synthesize eyesState=_eyesState;
@property(nonatomic) unsigned short sexType; // @synthesize sexType=_sexType;
@property(nonatomic) unsigned short ageType; // @synthesize ageType=_ageType;
@property(nonatomic) long long qualityMeasure; // @synthesize qualityMeasure=_qualityMeasure;
@property(nonatomic) long long clusterSequenceNumber; // @synthesize clusterSequenceNumber=_clusterSequenceNumber;
@property(nonatomic) unsigned long long algorithmVersion; // @synthesize algorithmVersion=_algorithmVersion;
@property(nonatomic) double poseYaw; // @synthesize poseYaw=_poseYaw;
@property(nonatomic) int trainingType; // @synthesize trainingType=_trainingType;
@property(nonatomic) long long nameSource; // @synthesize nameSource=_nameSource;
@property(copy, nonatomic) NSString *adjustmentVersion; // @synthesize adjustmentVersion=_adjustmentVersion;
@property(nonatomic) _Bool isRightEyeClosed; // @synthesize isRightEyeClosed=_isRightEyeClosed;
@property(nonatomic) _Bool isLeftEyeClosed; // @synthesize isLeftEyeClosed=_isLeftEyeClosed;
@property(nonatomic) double exposureScore; // @synthesize exposureScore=_exposureScore;
@property(nonatomic) double blurScore; // @synthesize blurScore=_blurScore;
@property(nonatomic) _Bool hasSmile; // @synthesize hasSmile=_hasSmile;
@property(nonatomic) _Bool isTooSmall; // @synthesize isTooSmall=_isTooSmall;
@property(nonatomic) _Bool manual; // @synthesize manual=_manual;
@property(nonatomic) _Bool isInTrash; // @synthesize isInTrash=_isInTrash;
@property(nonatomic) _Bool hidden; // @synthesize hidden=_hidden;
@property(nonatomic) double bodyHeight; // @synthesize bodyHeight=_bodyHeight;
@property(nonatomic) double bodyWidth; // @synthesize bodyWidth=_bodyWidth;
@property(nonatomic) double bodyCenterY; // @synthesize bodyCenterY=_bodyCenterY;
@property(nonatomic) double bodyCenterX; // @synthesize bodyCenterX=_bodyCenterX;
@property(nonatomic) double size; // @synthesize size=_size;
@property(nonatomic) double centerY; // @synthesize centerY=_centerY;
@property(nonatomic) double centerX; // @synthesize centerX=_centerX;
@property(nonatomic) short detectionType; // @synthesize detectionType=_detectionType;
@property(nonatomic) long long sourceHeight; // @synthesize sourceHeight=_sourceHeight;
@property(nonatomic) long long sourceWidth; // @synthesize sourceWidth=_sourceWidth;
@property(copy, nonatomic) NSString *personLocalIdentifier; // @synthesize personLocalIdentifier=_personLocalIdentifier;
@property(readonly, copy, nonatomic) NSString *localIdentifier; // @synthesize localIdentifier=_localIdentifier;
- (double)photosFaceRepresentationQuality;
- (double)photosFaceRepresentationRoll;
- (id)photosFaceRepresentationLocalIdentifier;
- (long long)photosFaceRepresentationClusterSequenceNumber;
- (long long)photosFaceRepresentationQualityMeasure;
- (_Bool)photosFaceRepresentationIsRightEyeClosed;
- (_Bool)photosFaceRepresentationIsLeftEyeClosed;
- (_Bool)photosFaceRepresentationHasSmile;
- (double)photosFaceRepresentationBlurScore;
- (double)photosFaceRepresentationSize;
- (double)photosFaceRepresentationCenterY;
- (double)photosFaceRepresentationCenterX;
- (long long)photosFaceRepresentationSourceHeight;
- (long long)photosFaceRepresentationSourceWidth;
- (long long)qualityMeasureWithCountOfFacesOnAsset:(unsigned long long)arg1;
- (id)gist;
- (struct CGRect)normalizedFaceRect;
- (_Bool)setCenterAndSizeFromNormalizedFaceRect:(struct CGRect)arg1;
- (void)replaceCoordinatesAndFeaturesFromDetectedFace:(id)arg1;
- (id)initWithLocalIdentifier:(id)arg1;

@end

